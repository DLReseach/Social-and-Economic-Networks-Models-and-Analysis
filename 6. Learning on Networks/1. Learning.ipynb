{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "- Bayesian learning\n",
    " - repeated actions, observe each other\n",
    " \n",
    "- DeGroot model\n",
    " - repeated communication, \"naive\" updating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Learning\n",
    "\n",
    "- Will society converge\n",
    "\n",
    "- Will they aggregate information properly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bala Goyal 98\n",
    "\n",
    "- n players in an undirected component g\n",
    "\n",
    "- Choose action A or B each period\n",
    "\n",
    "- A pays 1 for sure, B pays 2 with probability p and 0 with probability 1-p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning\n",
    "- Each period get a payoff based on choice\n",
    "\n",
    "- Also observe neighbors' choices\n",
    "\n",
    "- Maximize discounted stream of payoffs $E[\\sum_t \\delta^t \\pi_{it}]$\n",
    "\n",
    "- p is unkown takes on finite set of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges Bayesian learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposition\n",
    "\n",
    "- If p is not exactly 1/2, then with probability 1 there is a time such that all agents in a given component play just one action (and all play the same action) from that time onward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sketch of Proof\n",
    "\n",
    "- Suppose contrary\n",
    "\n",
    "- Some agent in some component plays B infinitely often\n",
    "\n",
    "- That agent will converge to true belief by the law of large numbers\n",
    "\n",
    "- Must be that belief converges to p>1/2, or that agent would stop playing B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play the right action?\n",
    "\n",
    "- If B is the right action then play the right action if converge to it, but might not\n",
    "\n",
    "- If A is the right action, then must converge to right action\n",
    "\n",
    "Consider the model of observational Bayesian learning on a network that we have discussed in which action A pays 1 for sure and action B pays 2 with an initially unknown probability p, and 0 with probability 1-p. Suppose that the society is in a network that is connected and all agents start with the same beliefs over which possible values p could have, and think p to be either 1/4 or 3/4.\n",
    "\n",
    "According the result we discussed, following statement(s) are correct:\n",
    " - If p<0.5, then with probability 1 all agents will play action A from some time onwards.\n",
    " - With probability 1, there is some time after which all agents will play the same action.\n",
    "\n",
    " Notice it could occur that all agents eventually play A even though B is actually the higher return action: provided they have sufficiently pessimistic beliefs about the return to playing B which could come from a sufficiently pessimistic prior or from bad luck on the initial outcomes from playing B.\n",
    "\n",
    " However, they cannot end up eventually playing B when it is the lower return action, since they would then eventually learn it to have a lower payoff. So in that case they eventually play A, and so the last statement is also correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability of Converging to \"correct\" action\n",
    "\n",
    "- Arbitrarily high if each action has some agent who initially has arbitrarily high prior that the action is the best one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "- Consensus action chosen\n",
    "\n",
    "- Not necessarily consensus belief\n",
    "\n",
    "- Speed of convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations\n",
    "\n",
    "- Homogeneity of actions and payoffs across players\n",
    "\n",
    "- What if heterogeneity?\n",
    "\n",
    "- Repeated actions over time\n",
    "\n",
    "- Stationarity\n",
    "\n",
    "- Networks are not playing role here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.4",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
