{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "- Part 1: Background and Fundamentals\n",
    " - Definitions and Characteristics of Networks(1,2)\n",
    " - Empirical Background(3)\n",
    " \n",
    "- **Part 2: Network Formation**\n",
    " - **Random Network Models (4,5)**\n",
    " - Strategic Network Models (6,11)\n",
    " \n",
    "- Part 3: Networks and Behavior\n",
    " - Diffusion and Learning (7,8)\n",
    " - Games on Networks (9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Static Models\n",
    "\n",
    "- Models to generate clustering\n",
    "\n",
    "- Models to generate other than Poisson degree distributions\n",
    "\n",
    "- Models to fit to data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Rewired lattice ‐Watts and Strogatz 98\n",
    "\n",
    "- Erdos‐Renyi model misses clustering\n",
    " - clustering is on the order of p; going to 0 unless average degree is becoming infinite (and highly so...)\n",
    "- Start with ring‐lattice and then randomly pick some links to rewire\n",
    " - start with high clustering but high diameter – as rewire enough links, get low diameter\n",
    " - don’t rewire too many, keep high clustering\n",
    " \n",
    "![](https://lh3.googleusercontent.com/YscwRCKEKZAh-qJwDx86ur6v6Ed1GldoCtJxj285EaZFHa7cOGPucnHz70ox2aVrKRbNjlJyMzmeChDQaMa8zH8QhCf-_QKolX43xrzyCywfPNIlg3aGejFBg665lExdDtcNpT-8pLQH1Yr3HA7CtaYfD9SkIkzMp9SPUkAyXFFek-LyGla7S4v_c3bY-FtmqITl3BUsa0mSYydsYfESH5h7RVRIxmXQXGGDpFpqR6ONlishk-Mp4p3y53vlVijZ3x3w3sQdgKoS2Ld7gmmugKl9WRutLY_FiOd1VsrtqVz-5k_G5Q_73VkQBCspXYBzX9m_DQpfoxZn_3scxgYAchQFIaOC4kheDS6K3BADzRe8V6QKPEJYZF2uQalpkgEErLijBAN5NLP4chbPdPIjCQgpRzyqtmmp1pKFbYTO-qG8Sez-1HLdF3pXrP4eX5ssYS_S2YufZTnXt_Bu4ltntZv9BFWFugSMcyJkkJfVkgLIGgZ5mdyKG5bGgSPjlDfhzuPP7W2ONTPok_GoSiuGbvHG2DBkfjsuDaUWobLbEJS762i_ZcaLIB_L8jAnl09lindn70av6b8HuFvf0IxLXGT8QEPUqdzAnnxXwOp1s6T71T-txPbM0PHvZb1l0loAYgqM0Ev2-d8QpQ61v3BEgDKBAwmuv-hqObKdZwjBVDeUEIyrIXNC3_u0=w855-h534-no)\n",
    "\n",
    "So here's just picture I drew of here of a set, a set of nodes.  So 25 nodes in a ring lattice. And so initially they're connected, each  node is connected to its two immediate neighbors.  So if we look here we have node one, and it's connected two and three, and also  connected to 25 and 24. Right?  So it's got these connections going here and here.  and then, each one of the nodes is, in terms of these in terms of the red, have  connections to the, the different neighbors, okay?  So we've, we've, we are connected to your 2 neighbors.  What that does is, in terms of this original lattice is give you very high  clustering. So 1 is connected to both 2 and 3, and 2  and 3 are connected to each other. 1 is connected to the 2 and 25, and 2 and  25 are connected to each other. And so forth.  So the clustering is is high when you start.  And then what you can do is is actually what I've done is this picture is rewire  the links but just to had a few random links.  Links. So let's just stick a few random links in  a network. And so what happens is initially if you  wanted to get without these initial, without these random links here, if you  wanted to get from node one to node 15 your path length would be quite far.  Right? You'd have to go sort of marching around  the circle. Your path length, especially if you  expanded this thing to be a much larger graph, your path link would be quite far.  \n",
    "\n",
    "By putting in these few connections, these extra ones, now to get from 1 to  15, you just go, you know, you've got a, a fairly short path, right?  You're connected in a, at a distance 4. to get from one to 14, you know, you're  connected at a distance three. So a few of these extra things allow you  to get so one can get to ten now through, in, in just two hops, and so forth.  So a few extra links actually dramatically shortens the average path  length. but it doesn't change the clustering too  much. Right?  And if you just, you know, deleted some links, but some of these new ones in, as  long as you're keeping it in the sort of sweet spot, what Watson Strogeth noticed  Wwas that you could just do a little bit of rewiring that shrinks the diameter  dramatically, and yet you keep reasonably high clustering.  Okay? Now of course, if you look at this  network, and you look at the, the shape of it, it's still not going to match a  lot of real-world networks. why not?  Well, because, you know, a lot of these nodes basically have degree four still,  or, or, you know, fairly regular. So it's, it's not going to fat, match the  fat tails and other kinds of things that we actually observe, but what it does do  is it begins to sort of answer some of the questions so that if that for some  reason we had high clustering on our, on, to start with in terms of some local  level And then we just add a few random links on top of that.  We can get at least two features in common, right, so it gives us some  explanation of how these things can begin to arise in common.  You don't need many random links to actually shorten average path length  dramtically. Now, you know, this model is far from one  we would want to take to data. But it begins to put some different  things together. And what we'll going to begin to do now  is start to enrich the models so that they're at the level where we can begin  to look at different things, put them in, take them to data and then ask things  about, you know, are we reproducing a lot of the features that we actually observe  in, in real world networks. So, we'll, we'll take a more detailed  look at random networks.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.0",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
